M8 - Despliegue Cloud AWS: Plan de Implementacion
Decisiones del usuario:

Routing API: Subdomain (api.cmep.dominio.com → backend, cmep.dominio.com → frontend)
AWS: Cuenta existente, necesita registrar dominio
Tracking: Crear docs/deployment/M8_tracking_deploy.md como checklist permanente
Alcance de Claude (Fase 1): Solo cambios de codigo que preparan el sistema para cloud.
Los cambios son condicionales — el sistema sigue funcionando 100% en local.

Estado Actual del Sistema (Hallazgos)
Archivos Criticos Analizados
Archivo	Estado	Impacto M8
backend/app/services/file_storage.py	Solo local filesystem	Necesita S3Storage
backend/app/config.py	Ya tiene FILE_STORAGE, S3_BUCKET	Listo, solo agregar cookie config
backend/app/database.py	Ya soporta MySQL + SQLite	Sin cambios
backend/app/api/auth.py	Cookie secure=False, samesite=lax	Necesita modo prod
backend/app/api/archivos.py	Usa save_file, read_file, delete_file	Sin cambios (usa abstraccion)
backend/app/main.py	CORS ya soporta lista de origenes	Sin cambios
backend/requirements.txt	Tiene asyncmy, pymysql. NO tiene boto3	Agregar boto3
backend/Dockerfile	Python 3.12-slim, tiene --reload	Quitar reload para prod
frontend/src/services/api.ts	Usa VITE_API_URL, credentials: "include"	Sin cambios
frontend/vite.config.ts	Config basica	Sin cambios
frontend/Dockerfile	Dev mode (npm run dev)	No se usa en AWS
infra/docker-compose.yml	MySQL + backend + frontend	Referencia local
infra/seed_dev.py	Soporta --mysql	Sin cambios
Lo que YA esta listo (no tocar)
config.py: DATABASE_URL resuelve MySQL o SQLite segun DB_URL
config.py: cors_origins_list ya splitea por coma
config.py: FILE_STORAGE y S3_BUCKET ya existen como settings
database.py: Pool config diferenciado para MySQL vs SQLite
api.ts: VITE_API_URL ya es configurable via env
requirements.txt: asyncmy y pymysql ya incluidos
seed_dev.py: Flag --mysql ya funciona
Lo que NECESITA cambios (Fase 1 - Claude)
file_storage.py: Agregar clase S3Storage + routing por config
requirements.txt: Agregar boto3
auth.py: Cookie condicional (secure/samesite segun APP_ENV)
Dockerfile backend: Quitar --reload, optimizar para prod
Nuevo infra/lambda_cleanup.py: Script Lambda para limpiar sesiones
Nuevo .env.example: Documentar variables de produccion
Analisis de Riesgo por Cambio
Cambio	Riesgo	Justificacion	Mitigacion
S3Storage en file_storage.py	BAJO	Se agrega clase nueva, funciones existentes solo cambian routing	FILE_STORAGE=local (default) mantiene comportamiento actual
boto3 en requirements.txt	BAJO	Dependencia nueva, no afecta imports existentes	Solo se importa si FILE_STORAGE=s3
Cookie condicional en auth.py	MEDIO	Cambio en flujo de auth	Condicional por APP_ENV, local sigue igual
Dockerfile sin --reload	BAJO	Solo afecta build de produccion	Desarrollo local no usa este Dockerfile
lambda_cleanup.py	NULO	Archivo nuevo, aislado	No interactua con el sistema
.env.example	NULO	Archivo nuevo de documentacion	Solo referencia
Conclusion: Los 117 tests existentes NO se ven afectados porque:

Tests usan FILE_STORAGE=local (default)
Tests usan SQLite (no MySQL)
Cookie changes son condicionales por APP_ENV=prod
boto3 no se importa en modo local
FASE 1: Preparacion del Codigo (Claude)
1.1 Agregar boto3 a requirements.txt
Archivo: backend/requirements.txt
Cambio: Agregar boto3>=1.35.0 en seccion Storage

1.2 Implementar S3Storage en file_storage.py
Archivo: backend/app/services/file_storage.py
Cambio: Refactorizar para soportar S3 y local:


- Mantener funciones existentes como LocalStorage
- Agregar S3Storage (boto3 client, upload, download, delete)
- Router: si FILE_STORAGE=s3 → S3, si no → local
- Import condicional de boto3 (solo si s3)
Funciones publicas (API no cambia):

generate_storage_name() - sin cambios
save_file(bytes, name) -> path - routing a local o S3
read_file(path) -> bytes - routing a local o S3
delete_file(path) - routing a local o S3
1.3 Cookie condicional en auth.py
Archivo: backend/app/api/auth.py
Cambio: Cookie settings basados en settings.APP_ENV:


# Produccion: secure=True, samesite="none", domain configurable
# Local: secure=False, samesite="lax" (actual)
Agregar setting COOKIE_DOMAIN en config.py (default vacío = no domain).

1.4 Optimizar Dockerfile backend para produccion
Archivo: backend/Dockerfile
Cambio:

Quitar --reload del CMD
Agregar workers configurables: --workers ${WORKERS:-1}
Mantener compatibilidad (funciona sin cambio de env)
1.5 Crear lambda_cleanup.py
Archivo nuevo: infra/lambda_cleanup.py

Conecta a MySQL via pymysql
DELETE FROM sessions WHERE expires_at < NOW()
Retorna conteo de sesiones eliminadas
Variables: DB_HOST, DB_USER, DB_PASS, DB_NAME desde env
1.6 Crear .env.example
Archivo nuevo: backend/.env.example

Documenta TODAS las variables con comentarios
Secciones: Database, App, Auth, CORS, Storage, Cookies
1.7 Crear docs/deployment/M8_tracking_deploy.md
Archivo nuevo: docs/deployment/M8_tracking_deploy.md

Checklist completa con todas las fases y sub-tareas
El usuario marca checkboxes conforme avanza
Incluye comandos copy-paste, notas y enlaces utiles
Orden de ejecucion:
requirements.txt (agregar boto3)
config.py (agregar COOKIE_DOMAIN)
file_storage.py (refactorizar con S3)
auth.py (cookie condicional)
Dockerfile (quitar reload)
lambda_cleanup.py (crear nuevo)
.env.example (crear nuevo)
docs/deployment/M8_tracking_deploy.md (crear tracking)
Ejecutar tests (verificar 117 pasan)
FASE 2: Infraestructura AWS (Usuario - via consola)
2.0 Registro de dominio (Prerequisito)
 Registrar dominio (Route 53 ~$12/año o proveedor externo)
 Opciones: Route 53 (integrado con AWS), Namecheap, GoDaddy, Cloudflare
 Anotar dominio elegido: ________________
2.1 Cuenta y alertas
 Configurar billing alert ($50 threshold)
 Seleccionar region (us-east-1 recomendado)
2.2 Red (VPC)
 Usar VPC default o crear nueva con 2 subnets (publica + privada)
 Security groups: SG-RDS (ingress 3306 desde SG-AppRunner)
2.3 Base de datos (RDS MySQL 8)
 Crear instancia: db.t3.micro, 20GB gp3, MySQL 8.0
 Subnet: privada (no acceso publico)
 Crear database: cmep_prod
 Crear usuario: cmep_user
 Backups automaticos: 7 dias
 Anotar endpoint: rds-endpoint.us-east-1.rds.amazonaws.com
2.4 Storage (S3)
 Crear bucket cmep-archivos-prod (privado, SSE-S3)
 Crear bucket cmep-frontend-prod (privado, para CloudFront OAC)
2.5 Secrets Manager
 Crear secreto cmep-prod-secrets con:

{
  "DB_URL": "mysql+asyncmy://cmep_user:PASS@rds-endpoint:3306/cmep_prod",
  "SESSION_SECRET": "<python -c 'import secrets; print(secrets.token_hex(32))'>",
  "S3_BUCKET": "cmep-archivos-prod"
}
2.6 IAM
 Crear rol cmep-apprunner-role:
S3: read/write en bucket archivos
Secrets Manager: read del secreto cmep
VPC: network access (para RDS)
2.7 ECR + Docker
 Crear repositorio ECR: cmep-backend
 Build local: docker build -t cmep-backend ./backend
 Tag y push a ECR
2.8 App Runner
 Crear servicio desde ECR image
 Config: 0.25 vCPU, 0.5GB RAM, port 8000
 Health check: GET /health
 Env vars desde Secrets Manager
 Configurar: APP_ENV=prod, FILE_STORAGE=s3, CORS_ORIGINS=https://cmep.tudominio.com
 Anotar URL publica de App Runner
2.9 Seed produccion
 Conectar a RDS (via bastion, Cloud9, o local con tunnel)
 Ejecutar: DB_URL=mysql+asyncmy://... python infra/seed_dev.py --mysql
FASE 3: Deploy Frontend (Usuario)
3.1 Build
 cd frontend && VITE_API_URL=https://api.cmep.tudominio.com npm run build
 Verificar que dist/ se genera correctamente
3.2 Upload a S3
 aws s3 sync dist/ s3://cmep-frontend-prod/ --delete
3.3 CloudFront
 Crear distribucion con origin S3 (OAC)
 Default root object: index.html
 Error pages: 403/404 → /index.html (status 200)
 Cache policy: CachingOptimized para static, CachingDisabled para index.html
3.4 SSL + DNS
 Solicitar certificado ACM para dominio
 DNS: cmep.tudominio.com → CloudFront
 DNS: api.cmep.tudominio.com → App Runner URL
3.5 Invalidar cache
 aws cloudfront create-invalidation --distribution-id XXXXX --paths "/*"
FASE 4: CORS y Cookies (Claude + Usuario)
4.1 Config backend (Claude ya preparo en Fase 1)
 Verificar CORS_ORIGINS incluye dominio produccion
 Verificar cookie: secure=true, samesite=none, domain=.tudominio.com
4.2 Test manual
 Abrir https://cmep.tudominio.com
 Login con admin@cmep.local / admin123
 Verificar cookie en DevTools > Application > Cookies
 Si falla: ajustar COOKIE_DOMAIN, CORS_ORIGINS
FASE 5: Monitoreo (Usuario)
 Verificar logs en CloudWatch (App Runner los envia automaticamente)
 Crear alarma: 5xx > 5 en 5 minutos
 Crear Lambda cmep-session-cleanup con infra/lambda_cleanup.py
 EventBridge rule: cada 6 horas → Lambda
 Verificar backups RDS activos
FASE 6: Smoke Test Produccion (Usuario)
 Login con cada rol (admin, operador, gestor, medico)
 Crear solicitud completa
 Flujo completo: REGISTRADO → ASIGNADO_GESTOR → PAGADO → ASIGNADO_MEDICO → CERRADO
 Upload y download de archivo
 Reportes admin cargan correctamente
 Verificar responsive en movil
 Cancelar una solicitud de prueba
 Override como admin
Costos Estimados AWS (Mensual)
Servicio	Config	Costo
RDS MySQL	db.t3.micro (free tier 12m)	$0-$15
App Runner	0.25 vCPU, 0.5GB	$5-$15
S3 (archivos)	< 1 GB	< $1
S3 (frontend)	< 50 MB	< $1
CloudFront	< 10 GB transfer	$0-$2
Secrets Manager	1 secreto	$0.40
CloudWatch	Logs basicos	$0-$5
Lambda	< 1000 invocaciones/mes	$0
Total		$7-$40/mes
Verificacion (Que nada se rompe)
Despues de Fase 1 (cambios de codigo):

cd backend && python -m pytest → 117 tests pasan
cd frontend && npx tsc -b → 0 errores TypeScript
Levantar local: python -m uvicorn app.main:app → funciona igual
Login, crear solicitud, subir archivo → todo funciona en local
Despues de Fase 2-3 (infra):

GET /health → {"ok": true}
GET /version → responde
Despues de Fase 4 (CORS/cookies):

Login desde frontend desplegado
Cookie visible en DevTools
Despues de Fase 6 (smoke test completo):

Flujo REGISTRADO → CERRADO funciona
Archivos suben y bajan
Reportes cargan